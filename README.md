# ğŸ  Pocket Planner

**AI-Powered Interior Design Assistant** â€” Upload a floor plan, get instant layout suggestions, and visualize your space in 3D.

![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)
![Next.js](https://img.shields.io/badge/Next.js-16-black?logo=next.js)
![Gemini](https://img.shields.io/badge/Google-Gemini%20AI-4285F4?logo=google)
![License](https://img.shields.io/badge/License-MIT-green)

---

## âœ¨ Features

### ğŸ” AI Vision Analysis
Upload a floor plan or room photo. Gemini Vision detects walls, windows, doors, and furniture â€” creating a digital twin of your space.

### ğŸ§  Generative Layout Designer
Get **3 distinct layout variations** tailored to your needs:
- **Work Focused** â€” Optimized for productivity with desk near natural light
- **Cozy & Relaxing** â€” Intimate arrangement prioritizing comfort
- **Creative & Bold** â€” Unconventional diagonal layouts for visual interest

### ğŸ¨ Photorealistic Previews
Each layout variation includes an AI-edited preview of your actual floor plan with furniture repositioned.

### ğŸ—ï¸ 3D Perspective View
Select a layout and generate a photorealistic 3D perspective render to feel the space before moving furniture.

### ğŸ’¬ Conversational Editor
Chat with your design! Natural language commands like:
- *"Move the desk closer to the window"*
- *"Rotate the bed 90 degrees"*
- *"Make it more cozy"*

---

## ğŸ–¼ï¸ How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Upload Floor   â”‚â”€â”€â”€â”€â–¶â”‚  AI Analyzes    â”‚â”€â”€â”€â”€â–¶â”‚  Generate 3     â”‚
â”‚  Plan Image     â”‚     â”‚  & Detects      â”‚     â”‚  Layout Options â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  Objects        â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chat Editor    â”‚â—€â”€â”€â”€â”€â”‚  3D Perspective â”‚â—€â”€â”€â”€â”€â”‚  Select Your    â”‚
â”‚  Fine-tune      â”‚     â”‚  Visualization  â”‚     â”‚  Favorite       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** â€” High-performance Python API
- **LangGraph** â€” Stateful agent orchestration
- **Google Gemini** â€” Vision analysis, layout reasoning, image generation
- **Shapely** â€” Geometric operations & collision detection
- **Pydantic** â€” Data validation

### Frontend
- **Next.js 16** â€” React framework with App Router
- **React 19** â€” UI components
- **Konva** â€” Canvas-based floor plan rendering
- **Tailwind CSS 4** â€” Styling
- **Axios** â€” API communication

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 20+
- Google AI API Key ([Get one here](https://aistudio.google.com/apikey))

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/pocket-planner.git
cd pocket-planner
```

### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
```

Edit `.env` with your API key:

```bash
# .env
GOOGLE_API_KEY=your_google_api_key_here
MODEL_NAME=gemini-2.5-pro
IMAGE_MODEL_NAME=gemini-2.5-flash-image
LOG_LEVEL=INFO
```

Start the backend:

```bash
uvicorn app.main:app --reload --port 8000
```

The API will be available at `http://localhost:8000`
- API Docs: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### 3. Frontend Setup

Open a new terminal:

```bash
cd frontend

# Install dependencies
npm install

# Configure environment
cp .env.example .env.local
```

Edit `.env.local`:

```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

Start the frontend:

```bash
npm run dev
```

Open `http://localhost:3000` in your browser.

---

## ğŸ“ Project Structure

```
pocket-planner/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/           # LangGraph agent nodes
â”‚   â”‚   â”‚   â”œâ”€â”€ designer_node.py      # Layout generation
â”‚   â”‚   â”‚   â”œâ”€â”€ vision_node.py        # Image analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ perspective_node.py   # 3D rendering
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_editor_node.py   # Conversational editing
â”‚   â”‚   â”‚   â””â”€â”€ graph.py              # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ core/             # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ constraints.py        # Spatial rules
â”‚   â”‚   â”‚   â”œâ”€â”€ geometry.py           # Collision detection
â”‚   â”‚   â”‚   â””â”€â”€ scoring.py            # Layout quality scoring
â”‚   â”‚   â”œâ”€â”€ models/           # Pydantic schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ api.py                # Request/Response models
â”‚   â”‚   â”‚   â”œâ”€â”€ room.py               # Room & furniture models
â”‚   â”‚   â”‚   â””â”€â”€ state.py              # Agent state
â”‚   â”‚   â”œâ”€â”€ routes/           # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze.py            # POST /analyze
â”‚   â”‚   â”‚   â”œâ”€â”€ optimize.py           # POST /optimize
â”‚   â”‚   â”‚   â”œâ”€â”€ render.py             # POST /render
â”‚   â”‚   â”‚   â””â”€â”€ chat.py               # POST /chat
â”‚   â”‚   â”œâ”€â”€ tools/            # Gemini tool wrappers
â”‚   â”‚   â”‚   â”œâ”€â”€ edit_image.py         # Image editing
â”‚   â”‚   â”‚   â””â”€â”€ generate_image.py     # Image generation
â”‚   â”‚   â”œâ”€â”€ config.py         # Settings & configuration
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/              # Next.js App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx              # Main application
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx            # Root layout
â”‚   â”‚   â”‚   â””â”€â”€ globals.css           # Global styles
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ CanvasOverlay.tsx     # Floor plan canvas
â”‚   â”‚   â”‚   â”œâ”€â”€ ImageUpload.tsx       # Image upload
â”‚   â”‚   â”‚   â”œâ”€â”€ LayoutSelector.tsx    # Layout variation cards
â”‚   â”‚   â”‚   â”œâ”€â”€ PerspectiveView.tsx   # 3D view display
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatEditor.tsx        # Chat interface
â”‚   â”‚   â”‚   â””â”€â”€ Sidebar.tsx           # Object list sidebar
â”‚   â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useAnalyze.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useOptimize.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ usePerspective.ts
â”‚   â”‚   â”‚   â””â”€â”€ useChatEdit.ts
â”‚   â”‚   â””â”€â”€ lib/              # Utilities
â”‚   â”‚       â”œâ”€â”€ api.ts                # API client
â”‚   â”‚       â””â”€â”€ types.ts              # TypeScript types
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ test_img.jpg          # Sample floor plan for testing
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/analyze` | Analyze floor plan, detect objects |
| `POST` | `/api/v1/optimize` | Generate 3 layout variations |
| `POST` | `/api/v1/render/perspective` | Generate 3D perspective view |
| `POST` | `/api/v1/chat/edit` | Process natural language edits |
| `GET` | `/health` | Health check |

### Example: Analyze a Floor Plan

```bash
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"image_base64": "your_base64_encoded_image"}'
```

### Example: Generate Layouts

```bash
curl -X POST http://localhost:8000/api/v1/optimize \
  -H "Content-Type: application/json" \
  -d '{
    "current_layout": [...],
    "room_dimensions": {"width_estimate": 100, "height_estimate": 100},
    "locked_ids": [],
    "image_base64": "your_base64_encoded_image"
  }'
```

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GOOGLE_API_KEY` | Google AI API key | Required |
| `MODEL_NAME` | Gemini model for reasoning | `gemini-2.5-flash` |
| `IMAGE_MODEL_NAME` | Gemini model for images | `gemini-2.5-flash-image` |
| `LOG_LEVEL` | Logging level | `INFO` |
| `LANGCHAIN_TRACING_V2` | Enable LangSmith tracing | `false` |
| `LANGCHAIN_API_KEY` | LangSmith API key | Optional |

---

## ğŸ§ª Development

### Running Tests

```bash
cd backend
pytest
```

### Code Formatting

```bash
# Backend
cd backend
black app/
ruff check app/

# Frontend
cd frontend
npm run lint
```

### Type Checking

```bash
# Backend
cd backend
mypy app/

# Frontend
cd frontend
npx tsc --noEmit
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Google Gemini](https://deepmind.google/technologies/gemini/) for AI capabilities
- [LangGraph](https://github.com/langchain-ai/langgraph) for agent orchestration
- [FastAPI](https://fastapi.tiangolo.com/) for the backend framework
- [Next.js](https://nextjs.org/) for the frontend framework

---

<p align="center">
  Made with â¤ï¸ for better living spaces
</p>